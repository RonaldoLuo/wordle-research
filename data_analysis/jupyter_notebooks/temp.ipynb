{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\adamk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adamk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Callable, List, Tuple, Dict, Union\n",
    "from ast import literal_eval\n",
    "from nltk.tokenize import SyllableTokenizer\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import gensim.downloader as api\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from scipy import stats\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "class WordleAnalyzer:\n",
    "    print(\"Loading models...\")\n",
    "    syllable_tokenizer = SyllableTokenizer()\n",
    "    glove_distance_model = api.load('glove-wiki-gigaword-300')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('punkt')\n",
    "\n",
    "    def __init__(self, csv_path: str, load_pickle: bool = True, pickle_name: str = \"pickled_data.pkl\", main_dir: str = \"data_analysis/generated_data\"):\n",
    "        \"\"\"Initialize the WordleAnalyzer with a CSV file path.\"\"\"\n",
    "        print(\"Loading data...\")\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        print(\"Preprocessing data...\")\n",
    "        self._preprocess_data()\n",
    "        self.metrics = {}\n",
    "        self.main_dir = main_dir\n",
    "        os.makedirs(main_dir, exist_ok=True)\n",
    "        self.pickle_path = os.path.join(main_dir, pickle_name)\n",
    "        \n",
    "        if load_pickle and os.path.exists(self.pickle_path):\n",
    "            self.load_pickled_metrics()\n",
    "\n",
    "    def save_plot(self, plot_func: Callable[[plt.Figure], None], filename: str) -> None:\n",
    "        \"\"\"Save a plot as PDF in the main directory.\"\"\"\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        plot_func(fig)\n",
    "        pdf_path = os.path.join(self.main_dir, f\"{filename}.pdf\")\n",
    "        plt.savefig(pdf_path, format='pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def _preprocess_data(self):\n",
    "        \"\"\"Preprocess the data for analysis.\"\"\"\n",
    "        # Convert string representations of lists to actual lists\n",
    "        self.df['wordle_guesses'] = self.df['wordle_guesses'].apply(literal_eval)\n",
    "        self.df['optimal'] = self.df['optimal'].apply(literal_eval)\n",
    "\n",
    "        # convert all string instances to lowercase in all of the dataframes\n",
    "        self.df['wordle_guesses'] = self.df['wordle_guesses'].apply(lambda x: [i.lower() for i in x])\n",
    "        self.df['optimal'] = self.df['optimal'].apply(lambda x: [[(word.lower(), count) for word, count in sublist] for sublist in x])\n",
    "        self.df['wordle_answer'] = self.df['wordle_answer'].apply(lambda x: x.lower())\n",
    "\n",
    "    def dump_pickle_metrics(self):\n",
    "        \"\"\"Save metrics to pickle file.\"\"\"\n",
    "        os.makedirs(os.path.dirname(self.pickle_path), exist_ok=True)\n",
    "        with open(self.pickle_path, 'wb') as f:\n",
    "            pickle.dump(self.metrics, f)\n",
    "            print(f\"Metrics saved to {self.pickle_path}\")\n",
    "\n",
    "    def load_pickled_metrics(self):\n",
    "        \"\"\"Load metrics from pickle file.\"\"\"\n",
    "        try:\n",
    "            with open(self.pickle_path, 'rb') as f:\n",
    "                self.metrics = pickle.load(f)\n",
    "                print(f\"Metrics loaded from {self.pickle_path}\")\n",
    "        except (FileNotFoundError, EOFError) as e:\n",
    "            print(f\"Error loading pickle file: {e}\")\n",
    "            self.metrics = {}\n",
    "    \n",
    "    @staticmethod\n",
    "    def levenshtein(source: str, target: str) -> int:\n",
    "        \"\"\"Calculate Levenshtein distance between two words.\"\"\"\n",
    "        if len(source) == 0:\n",
    "            return len(target)\n",
    "        if len(target) == 0:\n",
    "            return len(source)\n",
    "        if source[0] == target[0]:\n",
    "            return WordleAnalyzer.levenshtein(source[1:], target[1:])\n",
    "        direct_edit = WordleAnalyzer.levenshtein(source[1:], target[1:])\n",
    "        insert = WordleAnalyzer.levenshtein(source, target[1:])\n",
    "        delete = WordleAnalyzer.levenshtein(source[1:], target)\n",
    "        return 1 + min(delete, min(direct_edit, insert))\n",
    "    \n",
    "    @staticmethod\n",
    "    def avg_levenshtein_within(guess_list: List[str], start_idx: int) -> Union[float, str]:\n",
    "        \"\"\"Calculate average Levenshtein distance within a game's guesses. from guess i to guess 0 inclusive\"\"\"\n",
    "        if len(guess_list) == 1:\n",
    "            return \"no distance\"\n",
    "        total_distance = 0\n",
    "        comp = 0\n",
    "        for i in range(0, start_idx):\n",
    "            total_distance += WordleAnalyzer.levenshtein(guess_list[i], guess_list[i+1])\n",
    "            comp += 1\n",
    "        return total_distance / comp if comp > 0 else 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def common_syllables(word1: str, word2: str) -> int:\n",
    "        \"\"\"Calculate number of common syllables between two words.\"\"\"\n",
    "        syllables1 = set(WordleAnalyzer.syllable_tokenizer.tokenize(word1))\n",
    "        syllables2 = set(WordleAnalyzer.syllable_tokenizer.tokenize(word2))\n",
    "        return len(syllables1.intersection(syllables2))\n",
    "    \n",
    "    @staticmethod\n",
    "    def avg_common_syllables_within(guess_list: List[str], start_idx: int) -> Union[float, str]:\n",
    "        \"\"\"Calculate average number of common syllables within a game's guesses. from guess i to guess 0 inclusive\"\"\"\n",
    "        if len(guess_list) == 1:\n",
    "            return \"no common syllables\"\n",
    "        total_common_syllables = 0\n",
    "        comp = 0\n",
    "        for i in range(0, start_idx):\n",
    "            total_common_syllables += WordleAnalyzer.common_syllables(guess_list[i], guess_list[i+1])\n",
    "            comp += 1\n",
    "        return total_common_syllables / comp if comp > 0 else 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def shared_chars(word1: str, word2: str) -> int:\n",
    "        \"\"\"Calculate number of shared characters between two words.\"\"\"\n",
    "        return len(set(word1).intersection(set(word2)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def avg_shared_chars_within(guess_list: List[str], start_idx: int) -> Union[float, str]:\n",
    "        \"\"\"Calculate average number of shared characters within a game's guesses. from guess i to guess 0 inclusive\"\"\"\n",
    "        if len(guess_list) == 1:\n",
    "            return \"no shared characters\"\n",
    "        total_shared_chars = 0\n",
    "        comp = 0\n",
    "        for i in range(0, start_idx):\n",
    "            total_shared_chars += WordleAnalyzer.shared_chars(guess_list[i], guess_list[i+1])\n",
    "            comp += 1\n",
    "        return total_shared_chars / comp if comp > 0 else 0\n",
    "    \n",
    "\n",
    "    \n",
    "    def get_optimal_guesses(self, game_index: int) -> List[str]:\n",
    "        \"\"\"Get optimal guesses for game at specified index.\"\"\"\n",
    "        row = self.df.iloc[game_index]\n",
    "        actual_guesses = row['wordle_guesses']\n",
    "        games = []\n",
    "        for i in range(len(actual_guesses)-1):\n",
    "            games.append(actual_guesses[:i+1] + [row['optimal'][i][1][0]])\n",
    "        return games\n",
    "\n",
    "    def get_comparison_metrics(self, game_index: int) -> Dict[str, List[float]]:\n",
    "        \"\"\"Get comparison metrics for optimal vs actual game at specified index.\"\"\"\n",
    "        row = self.df.iloc[game_index]\n",
    "        actual_guesses = row['wordle_guesses']\n",
    "        optimal_sequence = self.get_optimal_guesses(game_index)\n",
    "        metrics = {\n",
    "            'actual_levenshtein': [],\n",
    "            'optimal_levenshtein': [],\n",
    "            'actual_syllables': [],\n",
    "            'optimal_syllables': [],\n",
    "            'actual_shared_chars': [],\n",
    "            'optimal_shared_chars': [],\n",
    "            'actual_glove_distance': [],\n",
    "            'optimal_glove_distance': []\n",
    "        }\n",
    "        \n",
    "        # Calculate metrics for actual and optimal guesses between i and i+1\n",
    "        for i in range(len(actual_guesses) - 1): # = len(optimal_sequence)\n",
    "            cur_game = optimal_sequence[i]\n",
    "            metrics['actual_levenshtein'].append(self.levenshtein(actual_guesses[i], actual_guesses[i+1]))\n",
    "            metrics['optimal_levenshtein'].append(self.levenshtein(cur_game[-1], cur_game[-2]))\n",
    "    \n",
    "            metrics['actual_syllables'].append(self.common_syllables(actual_guesses[i], actual_guesses[i+1]))\n",
    "            metrics['optimal_syllables'].append(self.common_syllables(cur_game[-1], cur_game[-2]))\n",
    "\n",
    "            metrics['actual_shared_chars'].append(self.shared_chars(actual_guesses[i], actual_guesses[i+1]))\n",
    "            metrics['optimal_shared_chars'].append(self.shared_chars(cur_game[-1], cur_game[-2]))\n",
    "\n",
    "            temp_actual = self.glove_distance(actual_guesses[i], actual_guesses[i+1], WordleAnalyzer.glove_distance_model)\n",
    "            temp_guess = self.glove_distance(cur_game[-1], cur_game[-2], WordleAnalyzer.glove_distance_model)\n",
    "            if temp_actual is not None and temp_guess is not None:\n",
    "                metrics['actual_glove_distance'].append(temp_actual)\n",
    "                metrics['optimal_glove_distance'].append(temp_guess)\n",
    "\n",
    "            # todo add semantic similarity\n",
    "            \n",
    "        self.metrics[game_index] = metrics\n",
    "        return metrics\n",
    "    \n",
    "    def plot_comparison_scatter(self, metric_type: str, n_games: int = None, sizes: Tuple[int, int] = (80, 800), save_pdf: bool = False):\n",
    "        \"\"\"Create scatter plot with regression line comparing optimal vs actual games.\"\"\"\n",
    "        if n_games is None:\n",
    "            n_games = len(self.df)\n",
    "\n",
    "        actual_data = []\n",
    "        optimal_data = []\n",
    "        sampled_indices = np.random.choice(self.df.index, size=min(n_games, len(self.df)), replace=False)\n",
    "        \n",
    "        # Collect data\n",
    "        for i in tqdm.tqdm(sampled_indices):\n",
    "            if i not in self.metrics:\n",
    "                self.get_comparison_metrics(i)\n",
    "            metrics = self.metrics[i]\n",
    "            \n",
    "            actual_key = f'actual_{metric_type}'\n",
    "            optimal_key = f'optimal_{metric_type}'\n",
    "            \n",
    "            for actual, optimal in zip(metrics[actual_key], metrics[optimal_key]):\n",
    "                if actual is not None and optimal is not None:\n",
    "                    actual_data.append(actual)\n",
    "                    optimal_data.append(optimal)\n",
    "\n",
    "        def create_plot(fig):\n",
    "            ax = fig.add_subplot(111)\n",
    "            \n",
    "            # Create DataFrame for seaborn\n",
    "            data = pd.DataFrame({\n",
    "                f'Optimal Game {metric_type.replace(\"_\", \" \").title()}': optimal_data,\n",
    "                f'Actual Game {metric_type.replace(\"_\", \" \").title()}': actual_data\n",
    "            })\n",
    "            \n",
    "            # Count occurrences for size\n",
    "            count_data = data.groupby([f'Optimal Game {metric_type.replace(\"_\", \" \").title()}', \n",
    "                                     f'Actual Game {metric_type.replace(\"_\", \" \").title()}']).size().reset_index(name='Count')\n",
    "            \n",
    "            # Create scatter plot\n",
    "            sns.scatterplot(data=count_data, \n",
    "                          x=f'Optimal Game {metric_type.replace(\"_\", \" \").title()}', \n",
    "                          y=f'Actual Game {metric_type.replace(\"_\", \" \").title()}', \n",
    "                          size='Count', sizes=sizes, legend=False, alpha=0.5, ax=ax)\n",
    "            \n",
    "            # Add regression line\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(optimal_data, actual_data)\n",
    "            line = slope * np.array([min(optimal_data), max(optimal_data)]) + intercept\n",
    "            ax.plot([min(optimal_data), max(optimal_data)], line, 'r-', \n",
    "                   label=f'Regression line (R² = {r_value**2:.3f})', color='green')\n",
    "            \n",
    "            # Add diagonal reference line\n",
    "            max_val = max(max(actual_data), max(optimal_data))\n",
    "            ax.plot([0, max_val], [0, max_val], 'r--', alpha=0.5, label='Perfect correlation')\n",
    "            \n",
    "            ax.set_title(f'Optimal vs Actual Game {metric_type.replace(\"_\", \" \").title()} Comparison')\n",
    "            ax.legend()\n",
    "\n",
    "        if save_pdf:\n",
    "            self.save_plot(create_plot, f\"scatter_{metric_type}\")\n",
    "        else:\n",
    "            create_plot(plt.figure(figsize=(10, 10)))\n",
    "            plt.show()\n",
    "\n",
    "    def plot_density_heatmap(self, metric_type: str, n_games: int = None, bins: int = 20, save_pdf: bool = False):\n",
    "        \"\"\"Create a heatmap showing the density of points with option to save as PDF.\"\"\"\n",
    "        if n_games is None:\n",
    "            n_games = len(self.df)\n",
    "            \n",
    "        actual_data = []\n",
    "        optimal_data = []\n",
    "        sampled_indices = np.random.choice(self.df.index, size=min(n_games, len(self.df)), replace=False)\n",
    "        \n",
    "        for i in tqdm.tqdm(sampled_indices):\n",
    "            if i not in self.metrics:\n",
    "                self.get_comparison_metrics(i)\n",
    "            metrics = self.metrics[i]\n",
    "            actual_values = metrics[f'actual_{metric_type}']\n",
    "            optimal_values = metrics[f'optimal_{metric_type}']\n",
    "            \n",
    "            for actual, optimal in zip(actual_values, optimal_values):\n",
    "                if actual is not None and optimal is not None:\n",
    "                    actual_data.append(actual)\n",
    "                    optimal_data.append(optimal)\n",
    "\n",
    "        def create_plot(fig):\n",
    "            ax = fig.add_subplot(111)\n",
    "            \n",
    "            hist, xedges, yedges = np.histogram2d(optimal_data, actual_data, bins=bins)\n",
    "            im = ax.imshow(hist.T, origin='lower', \n",
    "                          extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]], \n",
    "                          aspect='auto', cmap='YlOrRd')\n",
    "            \n",
    "            fig.colorbar(im, ax=ax, label='Count')\n",
    "            \n",
    "            max_val = max(max(actual_data), max(optimal_data))\n",
    "            min_val = min(min(actual_data), min(optimal_data))\n",
    "            ax.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.5)\n",
    "            \n",
    "            ax.set_ylabel(f'Actual Game {metric_type.replace(\"_\", \" \").title()}')\n",
    "            ax.set_xlabel(f'Optimal Game {metric_type.replace(\"_\", \" \").title()}')\n",
    "            ax.set_title(f'Density Heatmap: Optimal vs Actual Game {metric_type.replace(\"_\", \" \").title()}')\n",
    "\n",
    "        if save_pdf:\n",
    "            self.save_plot(create_plot, f\"heatmap_{metric_type}\")\n",
    "        else:\n",
    "            create_plot(plt.figure(figsize=(12, 10)))\n",
    "            plt.show()\n",
    "\n",
    "    def create_density_table(self, metric_type: str, n_games: int = None, bins: int = 10):\n",
    "        \"\"\"\n",
    "        Create a density table showing the count of points at each x,y coordinate bin.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        metric_type: str\n",
    "            'levenshtein', 'syllables', 'shared_chars', or 'glove_distance'\n",
    "        n_games: int, optional\n",
    "            Number of games to analyze\n",
    "        bins: int, optional\n",
    "            Number of bins for both x and y axes\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            A table showing the count of points in each bin\n",
    "        \"\"\"\n",
    "        if n_games is None:\n",
    "            n_games = len(self.df)\n",
    "            \n",
    "        actual_data = []\n",
    "        optimal_data = []\n",
    "        sampled_indices = np.random.choice(self.df.index, size=min(n_games, len(self.df)), replace=False)\n",
    "        \n",
    "        for i in tqdm.tqdm(sampled_indices):\n",
    "            if i not in self.metrics:\n",
    "                self.get_comparison_metrics(i)\n",
    "            metrics = self.metrics[i]\n",
    "            actual_key = f'actual_{metric_type}'\n",
    "            optimal_key = f'optimal_{metric_type}'\n",
    "            \n",
    "            actual_values = metrics[actual_key]\n",
    "            optimal_values = metrics[optimal_key]\n",
    "            \n",
    "            for actual, optimal in zip(actual_values, optimal_values):\n",
    "                if actual is not None and optimal is not None:\n",
    "                    actual_data.append(actual)\n",
    "                    optimal_data.append(optimal)\n",
    "        \n",
    "        # Create bins\n",
    "        max_val = max(max(actual_data), max(optimal_data))\n",
    "        min_val = min(min(actual_data), min(optimal_data))\n",
    "        \n",
    "        bin_edges = np.linspace(min_val, max_val, bins + 1)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        \n",
    "        # Create 2D histogram\n",
    "        hist, xedges, yedges = np.histogram2d(optimal_data, actual_data, \n",
    "                                            bins=[bin_edges, bin_edges])\n",
    "        \n",
    "        # Create DataFrame with bin centers as index/columns\n",
    "        density_df = pd.DataFrame(hist, \n",
    "                                index=pd.IntervalIndex.from_arrays(bin_edges[:-1], \n",
    "                                                                bin_edges[1:], \n",
    "                                                                closed='right'),\n",
    "                                columns=pd.IntervalIndex.from_arrays(bin_edges[:-1], \n",
    "                                                                bin_edges[1:], \n",
    "                                                                closed='right'))\n",
    "        \n",
    "        # Add row and column totals\n",
    "        density_df['Row Total'] = density_df.sum(axis=1)\n",
    "        density_df.loc['Column Total'] = density_df.sum()\n",
    "        #save density_df to csv\n",
    "        density_df.to_csv(f'{self.main_dir}\\\\density_table_{metric_type}.csv')\n",
    "        return density_df\n",
    "\n",
    "   \n",
    "    #####################################\n",
    "    # Function to calculate cosine similarity between two vectors\n",
    "    @staticmethod\n",
    "    def cosine_similarity(vec1, vec2):\n",
    "        return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
    "\n",
    "    # Function to compute distance between two words using GloVe\n",
    "    @staticmethod\n",
    "    def glove_distance(word1: str, word2: str, model, dec_place=2) -> float:\n",
    "        \"\"\"Compute distance between two words using GloVe embeddings.\"\"\"\n",
    "        if word1 in model and word2 in model:\n",
    "            vec1 = model[word1]\n",
    "            vec2 = model[word2]\n",
    "            similarity = WordleAnalyzer.cosine_similarity(vec1, vec2)\n",
    "            return round(1 - similarity, dec_place)\n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def avg_glove_distance_within(guess_list: List[str], start_idx: int, model, dec_place=2) -> Union[float, str]:\n",
    "        \"\"\"Calculate average GloVe distance within a game's guesses. from guess i to guess 0 inclusive\"\"\"\n",
    "        if len(guess_list) == 1:\n",
    "            return \"no distance\"\n",
    "        total_distance = 0\n",
    "        comp = 0\n",
    "        for i in range(0, start_idx):\n",
    "            distance = WordleAnalyzer.glove_distance(guess_list[i], guess_list[i+1], model, dec_place=100) # round at the end\n",
    "            if distance is not None:\n",
    "                total_distance += distance\n",
    "                comp += 1\n",
    "        return round(total_distance / comp, dec_place) if comp > 0 else 0 # we round here cuz physics and shit\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_semantic_similarities(word1: str, word2: str, dec_place=1) -> float:\n",
    "        synsets1 = wn.synsets(word1)\n",
    "        synsets2 = wn.synsets(word2)\n",
    "        \n",
    "        # Ensure words have synsets (not all words exist in WordNet)\n",
    "        if not synsets1 or not synsets2:\n",
    "            return None\n",
    "        \n",
    "        # Initialize maximum similarity\n",
    "        max_path_sim = 0\n",
    "        max_wup_sim = 0\n",
    "        max_lch_sim = 0\n",
    "        \n",
    "        # Iterate through all synset pairs and calculate the similarity\n",
    "        for synset1 in synsets1:\n",
    "            for synset2 in synsets2:\n",
    "                path_sim = synset1.path_similarity(synset2)\n",
    "                wup_sim = synset1.wup_similarity(synset2)\n",
    "                try:\n",
    "                    lch_sim = synset1.lch_similarity(synset2)\n",
    "                except:\n",
    "                    lch_sim = None\n",
    "                \n",
    "                # Update maximum similarity found\n",
    "                if path_sim is not None and path_sim > max_path_sim:\n",
    "                    max_path_sim = round(path_sim, dec_place)\n",
    "                if wup_sim is not None and wup_sim > max_wup_sim:\n",
    "                    max_wup_sim = round(wup_sim, dec_place)\n",
    "                if lch_sim is not None and lch_sim > max_lch_sim:\n",
    "                    max_lch_sim = round(lch_sim, dec_place)\n",
    "        \n",
    "        return {\n",
    "            'Path Similarity': max_path_sim,\n",
    "            'Wu-Palmer Similarity': max_wup_sim,\n",
    "            'Leacock-Chodorow Similarity': max_lch_sim\n",
    "        }\n",
    "\n",
    "    #####################################\n",
    "        \n",
    "    def get_popular_first_guesses(self, top_n: int = 10) -> List[Tuple[str, int]]:\n",
    "        \"\"\"Get the most popular first guesses.\"\"\"\n",
    "        first_guesses = [guesses[0] for guesses in self.df['wordle_guesses']]\n",
    "        return pd.Series(first_guesses).value_counts().head(top_n).items()\n",
    "    \n",
    "    def get_hard_mode_stats(self) -> Dict[str, float]:\n",
    "        \"\"\"Compare performance between hard mode and normal mode.\"\"\"\n",
    "        hard_mode_stats = self.df.groupby('hard_mode')['num_guesses'].agg(['mean', 'count']).to_dict('index')\n",
    "        return {\n",
    "            'hard_mode_avg': hard_mode_stats.get(True, {'mean': 0})['mean'],\n",
    "            'normal_mode_avg': hard_mode_stats.get(False, {'mean': 0})['mean'],\n",
    "            'hard_mode_games': hard_mode_stats.get(True, {'count': 0})['count'],\n",
    "            'normal_mode_games': hard_mode_stats.get(False, {'count': 0})['count']\n",
    "        }\n",
    "    \n",
    "    def get_average_guesses(self) -> float:\n",
    "        \"\"\"Calculate the average number of guesses across all games.\"\"\"\n",
    "        return self.df['num_guesses'].mean()\n",
    "    \n",
    "    def get_guess_distribution(self) -> Dict[int, int]:\n",
    "        \"\"\"Get the distribution of number of guesses.\"\"\"\n",
    "        return self.df['num_guesses'].value_counts().sort_index().to_dict()\n",
    "    \n",
    "    def analyze_optimal_choices(self, n_games: int = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Analyze how often players chose the optimal word for each guess position.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_games: int, optional\n",
    "            Number of games to analyze. If None, analyzes all games.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            DataFrame containing statistics about optimal word choices\n",
    "        \"\"\"\n",
    "        if n_games is None:\n",
    "            n_games = len(self.df)\n",
    "        \n",
    "        optimal_choices_data = []\n",
    "        sampled_indices = np.random.choice(self.df.index, size=min(n_games, len(self.df)), replace=False)\n",
    "        \n",
    "        # Collect data\n",
    "        for i in tqdm.tqdm(sampled_indices):\n",
    "            row = self.df.iloc[i]\n",
    "            player_guesses = row['wordle_guesses']\n",
    "            optimal_sequence = row['optimal']\n",
    "            \n",
    "            # For each guess position (except the first), check if player chose optimal word\n",
    "            for guess_idx in range(len(optimal_sequence)):\n",
    "                optimal_word = optimal_sequence[guess_idx][1][0].lower()  # Ensure lowercase\n",
    "                player_word = player_guesses[guess_idx + 1].lower() if guess_idx + 1 < len(player_guesses) else None\n",
    "                \n",
    "                optimal_choices_data.append({\n",
    "                    'game_id': i,\n",
    "                    'guess_position': guess_idx + 2,  # +2 because we're looking at next guess\n",
    "                    'player_word': player_word,\n",
    "                    'optimal_word': optimal_word,\n",
    "                    'chose_optimal': player_word == optimal_word if player_word is not None else False\n",
    "                })\n",
    "        \n",
    "        results_df = pd.DataFrame(optimal_choices_data)\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        summary_stats = (results_df\n",
    "                        .groupby('guess_position')\n",
    "                        .agg({\n",
    "                            'chose_optimal': ['count', 'sum', 'mean'],\n",
    "                            'game_id': 'nunique'\n",
    "                        })\n",
    "                        .round(3))\n",
    "        \n",
    "        summary_stats.columns = ['total_guesses', 'optimal_choices', \n",
    "                            'optimal_percentage', 'unique_games']\n",
    "        \n",
    "        # Create visualization\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        plt.bar(summary_stats.index, summary_stats['optimal_percentage'],\n",
    "                alpha=0.7)\n",
    "        \n",
    "        plt.xlabel('Guess Position')\n",
    "        plt.ylabel('Percentage of Optimal Choices')\n",
    "        plt.title('Optimal Word Choice Percentage by Guess Position')\n",
    "        \n",
    "        # Add percentage labels on top of bars\n",
    "        for i, v in enumerate(summary_stats['optimal_percentage']):\n",
    "            plt.text(i + 1, v + 0.01, f'{v:.1%}', ha='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return results_df, summary_stats\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Preprocessing data...\n",
      "Average guesses: 3.83\n",
      "\n",
      "Guess Distribution:\n",
      "1 guesses: 401 games\n",
      "2 guesses: 6896 games\n",
      "3 guesses: 23035 games\n",
      "4 guesses: 25578 games\n",
      "5 guesses: 13205 games\n",
      "6 guesses: 5944 games\n",
      "\n",
      "Most Popular First Guesses:\n",
      "stare: 4629 times\n",
      "crane: 2203 times\n",
      "raise: 2041 times\n",
      "slate: 1479 times\n",
      "adieu: 1399 times\n",
      "crate: 1252 times\n",
      "arise: 1216 times\n",
      "audio: 1109 times\n",
      "salet: 1062 times\n",
      "trace: 847 times\n",
      "\n",
      "Hard Mode vs Normal Mode:\n",
      "Hard Mode Average: 3.74 (57449 games)\n",
      "Normal Mode Average: 4.12 (17610 games)\n",
      "\n",
      "\n",
      "\n",
      "[['world', 'saice'], ['world', 'leafs', 'banal'], ['world', 'leafs', 'clang', 'naval'], ['world', 'leafs', 'clang', 'bantu', 'banal']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the analyzer with your CSV file\n",
    "analyzer = WordleAnalyzer(r'C:\\Users\\adamk\\Documents\\wordle_research\\wordle-research\\data_analysis\\data\\merged_data.csv', load_pickle=False)\n",
    "\n",
    "# Get basic statistics\n",
    "print(f\"Average guesses: {analyzer.get_average_guesses():.2f}\")\n",
    "\n",
    "# Get and print guess distribution\n",
    "distribution = analyzer.get_guess_distribution()\n",
    "print(\"\\nGuess Distribution:\")\n",
    "for guesses, count in distribution.items():\n",
    "    print(f\"{guesses} guesses: {count} games\")\n",
    "\n",
    "\n",
    "# Get popular first guesses\n",
    "print(\"\\nMost Popular First Guesses:\")\n",
    "for guess, count in analyzer.get_popular_first_guesses():\n",
    "    print(f\"{guess}: {count} times\")\n",
    "\n",
    "# Get hard mode statistics\n",
    "hard_mode_stats = analyzer.get_hard_mode_stats()\n",
    "print(\"\\nHard Mode vs Normal Mode:\")\n",
    "print(f\"Hard Mode Average: {hard_mode_stats['hard_mode_avg']:.2f} ({hard_mode_stats['hard_mode_games']} games)\")\n",
    "print(f\"Normal Mode Average: {hard_mode_stats['normal_mode_avg']:.2f} ({hard_mode_stats['normal_mode_games']} games)\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(analyzer.get_optimal_guesses(0))\n",
    "\n",
    "## how many guesses did optimal take vs how many guesses did the player take\n",
    "## how many time they chose optimal words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>author</th>\n",
       "      <th>wordle_guesses</th>\n",
       "      <th>num_guesses</th>\n",
       "      <th>wordle_answer</th>\n",
       "      <th>wordle_title</th>\n",
       "      <th>wordle_id</th>\n",
       "      <th>hard_mode</th>\n",
       "      <th>optimal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>u/McIgglyTuffMuffin</td>\n",
       "      <td>[cries, daddy, water, manor, bangs, banal]</td>\n",
       "      <td>6</td>\n",
       "      <td>banal</td>\n",
       "      <td>Wordle</td>\n",
       "      <td>201</td>\n",
       "      <td>False</td>\n",
       "      <td>[[(cries, 256), (tonal, 1)], [(daddy, 30), (ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>u/Rt002k</td>\n",
       "      <td>[mouse, trail, halal, papal, canal, banal]</td>\n",
       "      <td>6</td>\n",
       "      <td>banal</td>\n",
       "      <td>Wordle</td>\n",
       "      <td>201</td>\n",
       "      <td>True</td>\n",
       "      <td>[[(mouse, 327), (clint, 3)], [(trail, 5), (ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>22</td>\n",
       "      <td>u/renzaaa</td>\n",
       "      <td>[learn, roans, brant, grand, frank, crank]</td>\n",
       "      <td>6</td>\n",
       "      <td>crank</td>\n",
       "      <td>Wordle</td>\n",
       "      <td>203</td>\n",
       "      <td>False</td>\n",
       "      <td>[[(learn, 7), (caged, 1)], [(roans, 7), (caged...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>34</td>\n",
       "      <td>u/pummra</td>\n",
       "      <td>[leans, brand, grant, prank, frank, crank]</td>\n",
       "      <td>6</td>\n",
       "      <td>crank</td>\n",
       "      <td>Wordle</td>\n",
       "      <td>203</td>\n",
       "      <td>False</td>\n",
       "      <td>[[(leans, 12), (dicht, 1)], [(brand, 4), (capo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>51</td>\n",
       "      <td>u/2Legit2Quiz</td>\n",
       "      <td>[pleas, weird, rover, forte, borne, gorge]</td>\n",
       "      <td>6</td>\n",
       "      <td>gorge</td>\n",
       "      <td>Wordle</td>\n",
       "      <td>204</td>\n",
       "      <td>False</td>\n",
       "      <td>[[(pleas, 281), (ronte, 4)], [(weird, 44), (to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74962</th>\n",
       "      <td>82843</td>\n",
       "      <td>u/meganisawesome42</td>\n",
       "      <td>[aster, black, laugh, dally, naily, manly]</td>\n",
       "      <td>6</td>\n",
       "      <td>manly</td>\n",
       "      <td>Wordle</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>[[(aster, 130), (colin, 9)], [(black, 20), (di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74978</th>\n",
       "      <td>82859</td>\n",
       "      <td>u/khorijinn</td>\n",
       "      <td>[train, fancy, handy, mangy, manky, manly]</td>\n",
       "      <td>6</td>\n",
       "      <td>manly</td>\n",
       "      <td>Wordle</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>[[(train, 48), (algae, 2)], [(fancy, 8), (daal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74979</th>\n",
       "      <td>82860</td>\n",
       "      <td>u/EcoAffinity</td>\n",
       "      <td>[brand, wagon, nasty, hanky, fancy, manly]</td>\n",
       "      <td>6</td>\n",
       "      <td>manly</td>\n",
       "      <td>Wordle</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>[[(brand, 70), (laten, 4)], [(wagon, 16), (cym...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>82879</td>\n",
       "      <td>u/NASCARRULES88</td>\n",
       "      <td>[jesus, daddy, pappy, laggy, marly, manly]</td>\n",
       "      <td>6</td>\n",
       "      <td>manly</td>\n",
       "      <td>Wordle</td>\n",
       "      <td>2250</td>\n",
       "      <td>True</td>\n",
       "      <td>[[(jesus, 664), (cairn, 15)], [(daddy, 39), (c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75014</th>\n",
       "      <td>82896</td>\n",
       "      <td>u/Snoopyla1</td>\n",
       "      <td>[adieu, float, larch, walks, gayly, manly]</td>\n",
       "      <td>6</td>\n",
       "      <td>manly</td>\n",
       "      <td>Wordle</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>[[(adieu, 284), (torcs, 29)], [(float, 20), (s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5944 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       entry_id               author  \\\n",
       "1             2  u/McIgglyTuffMuffin   \n",
       "2             3             u/Rt002k   \n",
       "18           22            u/renzaaa   \n",
       "28           34             u/pummra   \n",
       "42           51        u/2Legit2Quiz   \n",
       "...         ...                  ...   \n",
       "74962     82843   u/meganisawesome42   \n",
       "74978     82859          u/khorijinn   \n",
       "74979     82860        u/EcoAffinity   \n",
       "74998     82879      u/NASCARRULES88   \n",
       "75014     82896          u/Snoopyla1   \n",
       "\n",
       "                                   wordle_guesses  num_guesses wordle_answer  \\\n",
       "1      [cries, daddy, water, manor, bangs, banal]            6         banal   \n",
       "2      [mouse, trail, halal, papal, canal, banal]            6         banal   \n",
       "18     [learn, roans, brant, grand, frank, crank]            6         crank   \n",
       "28     [leans, brand, grant, prank, frank, crank]            6         crank   \n",
       "42     [pleas, weird, rover, forte, borne, gorge]            6         gorge   \n",
       "...                                           ...          ...           ...   \n",
       "74962  [aster, black, laugh, dally, naily, manly]            6         manly   \n",
       "74978  [train, fancy, handy, mangy, manky, manly]            6         manly   \n",
       "74979  [brand, wagon, nasty, hanky, fancy, manly]            6         manly   \n",
       "74998  [jesus, daddy, pappy, laggy, marly, manly]            6         manly   \n",
       "75014  [adieu, float, larch, walks, gayly, manly]            6         manly   \n",
       "\n",
       "      wordle_title  wordle_id  hard_mode  \\\n",
       "1           Wordle        201      False   \n",
       "2           Wordle        201       True   \n",
       "18          Wordle        203      False   \n",
       "28          Wordle        203      False   \n",
       "42          Wordle        204      False   \n",
       "...            ...        ...        ...   \n",
       "74962       Wordle          6       True   \n",
       "74978       Wordle          6       True   \n",
       "74979       Wordle          6       True   \n",
       "74998       Wordle       2250       True   \n",
       "75014       Wordle          6       True   \n",
       "\n",
       "                                                 optimal  \n",
       "1      [[(cries, 256), (tonal, 1)], [(daddy, 30), (ta...  \n",
       "2      [[(mouse, 327), (clint, 3)], [(trail, 5), (ban...  \n",
       "18     [[(learn, 7), (caged, 1)], [(roans, 7), (caged...  \n",
       "28     [[(leans, 12), (dicht, 1)], [(brand, 4), (capo...  \n",
       "42     [[(pleas, 281), (ronte, 4)], [(weird, 44), (to...  \n",
       "...                                                  ...  \n",
       "74962  [[(aster, 130), (colin, 9)], [(black, 20), (di...  \n",
       "74978  [[(train, 48), (algae, 2)], [(fancy, 8), (daal...  \n",
       "74979  [[(brand, 70), (laten, 4)], [(wagon, 16), (cym...  \n",
       "74998  [[(jesus, 664), (cairn, 15)], [(daddy, 39), (c...  \n",
       "75014  [[(adieu, 284), (torcs, 29)], [(float, 20), (s...  \n",
       "\n",
       "[5944 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print maximum number of guesses\n",
    "analyzer.df['num_guesses'].max()\n",
    "# print game with maximum number of guesses\n",
    "analyzer.df[analyzer.df['num_guesses'] == analyzer.df['num_guesses'].max()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
