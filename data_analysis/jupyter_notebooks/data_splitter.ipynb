{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 50 batches and save them into new csv's\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 50 batches\n",
    "\n",
    "def split_data(data, store_dir=\"data_analysis/data/data_batches\", num_batches=50):\n",
    "    total_rows = len(data)\n",
    "    batch_size = total_rows // num_batches\n",
    "    for i in range(50):\n",
    "        start = i * batch_size\n",
    "        # Ensure the last batch captures any remaining rows\n",
    "        end = start + batch_size if i < 49 else total_rows\n",
    "        data_batch = data.iloc[start:end]\n",
    "        data_batch.to_csv(os.path.join(store_dir, f'data_batch_{i}.csv'), index=False, header=True)\n",
    "\n",
    "\n",
    "def check_line_count(directory, initial_csv):\n",
    "    # Load the initial data and get the number of rows (excluding header)\n",
    "    initial_data = pd.read_csv(initial_csv)\n",
    "    initial_row_count = len(initial_data)\n",
    "\n",
    "    # Initialize a counter for total rows from the CSVs in the directory\n",
    "    total_row_count = 0\n",
    "\n",
    "    # Loop through all files in the specified directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            # Read each CSV file and count the number of rows (excluding header)\n",
    "            batch_data = pd.read_csv(file_path)\n",
    "            total_row_count += len(batch_data)\n",
    "\n",
    "    # Print the results\n",
    "    print(f'Initial row count (excluding header): {initial_row_count}')\n",
    "    print(f'Total row count from CSVs in directory: {total_row_count}')\n",
    "\n",
    "    # Check if the counts match\n",
    "    if initial_row_count == total_row_count:\n",
    "        print(\"All data has been successfully split and no rows have been lost.\")\n",
    "    else:\n",
    "        print(\"Warning: The counts do not match. Data may be missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "init_file = 'data_analysis/data/data_1.csv'\n",
    "store_dir = 'data_analysis/data/data_batches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "data = pd.read_csv(init_file)\n",
    "split_data(data, store_dir=store_dir, num_batches=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check line count make sure all data is there\n",
    "check_line_count(store_dir, init_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
